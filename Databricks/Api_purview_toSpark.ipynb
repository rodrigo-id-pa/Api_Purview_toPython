{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OBS: \n",
    "# Precisa do azure configurado\n",
    "# Precisa do purview configurado no azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from pyapacheatlas.auth import ServicePrincipalAuthentication\n",
    "from pyapacheatlas.core import PurviewClient, AtlasEntity, AtlasProcess, TypeCategory\n",
    "from pyapacheatlas.core.typedef import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def azuread_auth(tenant_id: str, client_id: str, client_secret: str, resource_url: str):\n",
    "    \n",
    "    url = f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\"\n",
    "    payload= f'grant_type=client_credentials&client_id={client_id}&client_secret={client_secret}&resource={resource_url}'\n",
    "    headers = {\n",
    "        'Content-Type': 'application/x-www-form-urlencoded'\n",
    "    }\n",
    "    \n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    access_token = json.loads(response.text)['access_token']\n",
    "    \n",
    "    return access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purview_auth(tenant_id: str, client_id: str, client_secret: str, data_catalog_name: str):\n",
    "  \n",
    "    oauth2 = ServicePrincipalAuthentication(\n",
    "        tenant_id = tenant_id,\n",
    "        client_id = client_id,\n",
    "        client_secret = client_secret\n",
    "    )\n",
    "    client = PurviewClient(\n",
    "        account_name = data_catalog_name,\n",
    "        authentication = oauth2\n",
    "    )\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrir conexão com o datalake\n",
    "spark.conf.set(\n",
    "  \"\", # Endpoint do datalake\n",
    "  \"\" # Acess Key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar json com as chaves de acesso do azure e purview\n",
    "\n",
    "# Recuperar caminho até o json de parâmetros da Autentificação do Purview\n",
    "path_params = dbutils.fs.ls('''path do json no azure''')\n",
    "\n",
    "# Recuperar dados do json de parâmetros da Autentificação do Purview\n",
    "parameters = spark.read.format(\"json\").load(path_params)\n",
    "\n",
    "client_id = parameters.select('client_id').collect()[0][0]\n",
    "client_secret = parameters.select('client_secret').collect()[0][0]\n",
    "data_catalog_name = parameters.select('data_catalog_name').collect()[0][0]\n",
    "resource_url = parameters.select('resource_url').collect()[0][0]\n",
    "tenant_id = parameters.select('tenant_id').collect()[0][0]\n",
    "\n",
    "# Recuperar objetos de autenticação\n",
    "azuread_access_token = azuread_auth(tenant_id, client_id, client_secret, resource_url)\n",
    "purview_client = purview_auth(tenant_id, client_id, client_secret, data_catalog_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_response_values = []\n",
    "def requestId(endpoint: str, url: str, response: any, payload: any):\n",
    "    endpoint = endpoint\n",
    "    url = url\n",
    "    payload = payload\n",
    "    headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {azuread_access_token}'\n",
    "    }\n",
    "    response = response\n",
    "    list_response_values.append(response.text)\n",
    "    \n",
    "    if(response.status_code != 200):\n",
    "      print(\"Status:\",response.status_code, \"Erro no código\")\n",
    "    else:\n",
    "      print(\"Status:\",response.status_code, \"Ok\", list_response_values)\n",
    "    \n",
    "    return list_response_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "endpoint = \"https://{data_catalog_name}.purview.azure.com/\"\n",
    "url = f\"{endpoint}/catalog/api/search/query?api-version=2021-05-01-preview\"\n",
    "method = \"POST\"\n",
    "payload = json.dumps({\n",
    "        \"orderby\":[\"name\"],\n",
    "        \"limit\": 1000,\n",
    "        \"keywords\": None,\n",
    "        \"filter\": {\n",
    "            \"classification\": \"\",\n",
    "            \"includeSubClassifications\": True,\n",
    "            \"collectionId\": \"\"\n",
    "        }\n",
    "    })\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "requestId(endpoint, url, response, payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_value = pd.DataFrame(json.loads(list_response_values[0])['value'])\n",
    "#df_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = df_value['id']\n",
    "#df_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_response = []\n",
    "for id_ in df_id:\n",
    "    endpoint = \"https://{data_catalog_name}.purview.azure.com/\"\n",
    "    url = f\"{endpoint}/catalog/api/atlas/v2/entity/bulk?excludeRelationshipTypes=dataset_process_inputs&excludeRelationshipTypes=process_parent&excludeRelationshipTypes=direct_lineage_dataset_dataset&guid={id_}&includeTermsInMinExtInfo=false&minExtInfo=false&ignoreRelationships=false\"\n",
    "    payload = azuread_access_token\n",
    "    \n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    list_response.append(response.text)\n",
    "    requestId(endpoint, url, response, payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_list_res_referredEntities = pd.DataFrame()\n",
    "\n",
    "for x in list_response:\n",
    "    df_list = pd.DataFrame(json.loads(x)['referredEntities']).loc[['attributes','classifications'],:].transpose()\n",
    "    \n",
    "    df_list_res_referredEntities = pd.concat([df_list_res_referredEntities, df_list])\n",
    "\n",
    "\n",
    "df_list_res_referredEntities.reset_index(inplace=True)\n",
    "df_list_res_referredEntities = df_list_res_referredEntities.rename(columns = {'index':'IDs'})\n",
    "\n",
    "#df_list_res_referredEntities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_columns = df_list_res_referredEntities\n",
    "\n",
    "df_columns['classificação'] = ''\n",
    "\n",
    "for i in range(df_columns.shape[0]):\n",
    "    df_columns.loc[i,'attributes'] = df_columns.loc[i,'attributes']['name']\n",
    "    \n",
    "    if pd.isna(df_columns.loc[:,'classifications'].iloc[i]):\n",
    "        df_columns.loc[:,'classificação'].iloc[i] = 'Sem classificação' \n",
    "    else:\n",
    "        df_columns.loc[:,'classificação'].iloc[i] = df_columns.classifications.iloc[i][0]['typeName']\n",
    "\n",
    "#df_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col = df_columns.loc[:, ['IDs','attributes', 'classificação']]\n",
    "#df_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tables = df_value.loc[:, ['id','name', 'classification']]\n",
    "#df_tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tables['classificação2'] = ''\n",
    "\n",
    "for counter, list_ in enumerate(df_tables['classification']):\n",
    "    if('sua classificação' in list_ and 'sua classificação' in list_):\n",
    "        df_tables.loc[counter, 'classificação2'] = 'sua classificação'\n",
    "\n",
    "#df_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tab = df_tables.loc[:, ['id', 'name', 'classificação2']]\n",
    "#df_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - criando dataframe\n",
    "# 2 - trazendo id, nome e classificação das tabelas\n",
    "# 3 - criando nova coluna com o id das colunas\n",
    "# 4 - igualando o id da tabela com a coluna para fazer o merge\n",
    "\n",
    "df_tab.loc[:,'Id_simplificado'] = ''\n",
    "for count, item in enumerate(df_tab.id):\n",
    "    df_tab.loc[:,'Id_simplificado'].iloc[count] = item[:33]\n",
    "\n",
    "df_col.loc[:,'Id_simplificado'] = ''    \n",
    "for count, item in enumerate(df_col.IDs):\n",
    "    df_col.loc[:,'Id_simplificado'].iloc[count] = item[:33]\n",
    "    \n",
    "    \n",
    "#print(df_col.head())\n",
    "#df_tab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table_merge = df_tab.merge(df_col, left_on='Id_simplificado', right_on='Id_simplificado')\n",
    "#table_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_final = table_merge[['name', 'classificação2', 'attributes', 'classificação']].rename(columns={'name':'Tabela', 'classificação2':'Classificação', 'attributes':'Colunas', 'classificação':'Classificação'})\n",
    "\n",
    "table_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_file(dataframe, ext_target, target, new_name):\n",
    "  df_res = dataframe\n",
    "  df_res.to_csv('/dbfs/tmp/purview/'+new_name+'.'+ext_target, sep=',', index=False)\n",
    "  dbutils.fs.mv(\"/tmp/purview/\"+new_name+'.'+ext_target, target+'/'+new_name+'.'+ext_target)\n",
    "  print ('Novo arquivo {} salvo em {}'.format(new_name, target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = table_final\n",
    "ext_target=\"csv\"\n",
    "path_raw = 'path do azure'\n",
    "new_name = f\"nome do arquivo csv\"\n",
    "export_file(dataframe, ext_target, path_raw, new_name)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
